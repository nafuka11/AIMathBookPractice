{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 6 実践編2\n",
    "\n",
    "## 6-4 文章を品詞分解"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import MeCab\n",
    "\n",
    "# 解析用のインスタンスを生成\n",
    "mecab = MeCab.Tagger()\n",
    "text = \"私たちは人工知能を作るために勉強する\"\n",
    "# 解析結果を双方向リストの先頭ノードとして取得\n",
    "node = mecab.parseToNode(text)\n",
    "\n",
    "# \"BOS/EOS,*...\"は文頭, 文末を表す特殊なNode\n",
    "while node:\n",
    "    # surface: 単語, feature: 品詞\n",
    "    print(f\"{node.surface}\\t{node.feature}\")\n",
    "    node = node.next"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tBOS/EOS,*,*,*,*,*,*,*,*\n",
      "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
      "たち\t名詞,接尾,一般,*,*,*,たち,タチ,タチ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "作る\t動詞,自立,*,*,五段・ラ行,基本形,作る,ツクル,ツクル\n",
      "ため\t名詞,非自立,副詞可能,*,*,*,ため,タメ,タメ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "勉強\t名詞,サ変接続,*,*,*,*,勉強,ベンキョウ,ベンキョー\n",
      "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "\tBOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "text = \"にわにはにわにわとりがいる\"\n",
    "node = mecab.parseToNode(text)\n",
    "# 文頭を表す特殊なノードを読み飛ばす\n",
    "node = node.next\n",
    "\n",
    "while node.next:\n",
    "    print(f\"{node.surface}\\t{node.feature}\")\n",
    "    node = node.next"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "わに\t名詞,一般,*,*,*,*,わに,ワニ,ワニ\n",
      "はにわ\t名詞,一般,*,*,*,*,はにわ,ハニワ,ハニワ\n",
      "にわとり\t名詞,一般,*,*,*,*,にわとり,ニワトリ,ニワトリ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "いる\t動詞,自立,*,*,一段,基本形,いる,イル,イル\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 注意：事前にdownload_rawdata.sh を実行して、3作家の文章をダウンロードしてください\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "DATASET_DIR = \"./dataset/raw_datas\"\n",
    "STOPWORD_FILE = \"./origin_stopwords.txt\"\n",
    "UNIQUE_FILE = \"./origin_words.txt\"\n",
    "CORPUS_FILE = \"./dataset/corpus.csv\"\n",
    "\n",
    "def main():\n",
    "    # 分かち書きするオプションを指定してインスタンス生成\n",
    "    mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "    files = list(Path(DATASET_DIR).glob(\"*.txt\"))\n",
    "    authors = {file.stem: [] for file in files}\n",
    "    cleaned_all_data = []\n",
    "    print(authors)\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            cleaned_text = clean_text(mecab, f.read())\n",
    "            authors[file.stem] = cleaned_text\n",
    "            cleaned_all_data += cleaned_text\n",
    "            print(f\"{file.stem}: {cleaned_text[:1]}\")\n",
    "\n",
    "    make_stopdic(cleaned_all_data)\n",
    "    make_corpus_file(cleaned_all_data, authors)\n",
    "\n",
    "\n",
    "def clean_text(mecab: MeCab.Tagger, raw_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    ルビや入力者注を削除して一文毎に分割,分かち書き\n",
    "    \"\"\"\n",
    "    text = raw_text.replace('\\n', '').replace('\\u3000', '') # 改行, 全角スペース削除\n",
    "    text = re.sub('[［《]', '／', text) # 開始括弧を全て／に\n",
    "    text = re.sub('[］》]', '＼', text) # 終了括弧を全て＼に\n",
    "    text = re.sub('／[^＼]*?＼', '', text) # 括弧とその間の文字を削除\n",
    "    text = text.replace('。', '。\\n') # 。に改行追加\n",
    "    text = text.replace('「', '') # 「を削除\n",
    "    text = text.replace('」', '\\n').split('\\n') # 」を削除して代わりに改行を追加\n",
    "\n",
    "    return [mecab.parse(sentence).split(' ') for sentence in text if sentence]\n",
    "\n",
    "\n",
    "def make_stopdic(lines: List[str]):\n",
    "    \"\"\"\n",
    "    空白区切りの文の集まりのテキストのリストからストップワードの辞書を作成する。\n",
    "    \"\"\"\n",
    "    # AIMathBookのリポジトリでは、make_stopdicの後にclean()していない文章で再度辞書を作成している\n",
    "    # (02_nlp/cleaning.ipynbのIn [5, 6])\n",
    "    # おそらくmake_stopdicする方が本来の意図だと思うので、再度辞書は作成していません\n",
    "    calc_words = Counter()\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            calc_words[word] += 1\n",
    "    sorted_stop = calc_words.most_common()\n",
    "    print(f\"ユニークな単語の数(len(sorted_stop)): {len(sorted_stop)}\")\n",
    "\n",
    "    freq_num = int(len(sorted_stop) * 0.03)\n",
    "    print(f\"ストップワードとして除去する単語の数(freq_num): {freq_num}\")\n",
    "\n",
    "    stop_words = []\n",
    "    print(\"High frequency words:\")\n",
    "    for i in range(freq_num + 1):\n",
    "        stop_words.append(sorted_stop[i][0])\n",
    "        print(f\"{sorted_stop[i][0]}\\t{sorted_stop[i][1]}\")\n",
    "\n",
    "    # 作成したストップワードの辞書の保存\n",
    "    with open(STOPWORD_FILE, 'w') as f:\n",
    "        f.write('\\n'.join(stop_words))\n",
    "\n",
    "\n",
    "def remove_stopword_bydic(text: List[str]):\n",
    "    \"\"\"\n",
    "    辞書によるストップワードの除去\n",
    "    \"\"\"\n",
    "    # 読み込むストップワード辞書の指定。\n",
    "    with open(STOPWORD_FILE, \"r\") as f:\n",
    "        data = f.read()\n",
    "        stopwords = data.split('\\n')\n",
    "    lines = []\n",
    "    for line in text:\n",
    "        words = []\n",
    "        for word in line:\n",
    "            if word not in stopwords:\n",
    "                words.append(word)\n",
    "        lines.append(words)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def make_corpus_file(cleaned_data: List[List[str]], authors):\n",
    "    \"\"\"\n",
    "    コーパスファイルを作成する\n",
    "    \"\"\"\n",
    "    removed_data = remove_stopword_bydic(cleaned_data)\n",
    "\n",
    "    unique_words = set()\n",
    "    for line in removed_data:\n",
    "        for word in line:\n",
    "            unique_words.add(word)\n",
    "\n",
    "    print(f\"ストップワードを除外した後の行数：{len(removed_data)}\")\n",
    "    print(f\"ユニークな単語の数：{len(unique_words)}\")\n",
    "    with open(UNIQUE_FILE, 'w') as f:\n",
    "        f.write('\\n'.join(list(unique_words)))\n",
    "    corpus_data = []\n",
    "    for author, data in authors.items():\n",
    "        data = remove_stopword_bydic(data)\n",
    "        for line in data:\n",
    "            corpus_data.append(author + ',' + ' '.join(line))\n",
    "    # 作成したコーパスの保存\n",
    "    with open(CORPUS_FILE, 'w') as f:\n",
    "        f.write(''.join(corpus_data))\n",
    "\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'akutagawa': [], 'mori': [], 'dazai': []}\n",
      "akutagawa: [['保吉', 'は', 'ずつ', 'と', '以前', 'から', 'この', '店', 'の', '主人', 'を', '見知', 'つ', 'て', 'ゐる', '。', '\\n']]\n",
      "mori: [['従四', '｜', '位', '下', '左', '近衛', '少将', '兼', '｜', '越中', '守', '細川', '忠利', 'は', '、', '寛永', '十', '八', '年', '｜', '辛', '巳', 'の', '春', '、', 'よそ', 'より', 'は', '早く', '咲く', '領地', '｜', '肥後', '国', 'の', '花', 'を', '見', 'すて', 'て', '、', '五', '十', '四', '万', '石', 'の', '大名', 'の', '晴れ晴れ', 'し', 'い', '行列', 'に', '前後', 'を', '囲ま', 'せ', '、', '南', 'より', '北', 'へ', '歩み', 'を', '運ぶ', '春', 'とともに', '、', '江戸', 'を', '志し', 'て', '参勤', 'の', '途', 'に', '上ろ', 'う', 'と', 'し', 'て', 'いる', 'うち', '、', 'はから', 'ず', '病', 'に', 'かかっ', 'て', '、', '典', '医', 'の', '方', '剤', 'も', '功', 'を', '奏', 'せ', 'ず', '、', '日', 'に', '増し', '重く', 'なる', 'ばかり', 'な', 'ので', '、', '江戸', 'へ', 'は', '出発', '日', '延べ', 'の', '飛脚', 'が', '立つ', '。', '\\n']]\n",
      "dazai: [['賭', '弓', 'に', '、', 'わな', 'なく', '久し', 'う', 'あり', 'て', '、', 'は', 'づしたる', '矢', 'の', '、', 'もて', '離れ', 'て', 'こと', 'かた', 'へ', '行き', 'たる', '。', '\\n']]\n",
      "ユニークな単語の数(len(sorted_stop)): 13928\n",
      "ストップワードとして除去する単語の数(freq_num): 417\n",
      "High frequency words:\n",
      "、\t13315\n",
      "\n",
      "\t8876\n",
      "の\t8746\n",
      "。\t8104\n",
      "に\t6641\n",
      "は\t6285\n",
      "て\t5904\n",
      "を\t5352\n",
      "た\t5256\n",
      "が\t3337\n",
      "と\t3001\n",
      "で\t2844\n",
      "も\t2036\n",
      "し\t1975\n",
      "ない\t1192\n",
      "な\t1096\n",
      "だ\t1009\n",
      "ある\t936\n",
      "か\t917\n",
      "から\t876\n",
      "い\t846\n",
      "へ\t814\n",
      "まし\t725\n",
      "いる\t709\n",
      "その\t692\n",
      "う\t691\n",
      "ます\t664\n",
      "人\t653\n",
      "こと\t625\n",
      "私\t542\n",
      "それ\t528\n",
      "よう\t520\n",
      "ん\t518\n",
      "云\t513\n",
      "もの\t513\n",
      "れ\t513\n",
      "一\t480\n",
      "ば\t468\n",
      "です\t465\n",
      "この\t448\n",
      "する\t408\n",
      "さ\t401\n",
      "ぬ\t400\n",
      "二\t396\n",
      "事\t396\n",
      "ふ\t363\n",
      "つて\t351\n",
      "お\t348\n",
      "来\t336\n",
      "何\t324\n",
      "あり\t319\n",
      "ながら\t306\n",
      "ず\t302\n",
      "なっ\t298\n",
      "男\t293\n",
      "中\t286\n",
      "見\t281\n",
      "十\t275\n",
      "女\t273\n",
      "御\t270\n",
      "三\t269\n",
      "せ\t266\n",
      "つ\t260\n",
      "時\t259\n",
      "なら\t259\n",
      "あっ\t259\n",
      "？\t257\n",
      "ね\t255\n",
      "ませ\t252\n",
      "そう\t252\n",
      "よ\t252\n",
      "まで\t247\n",
      "あの\t246\n",
      "顔\t246\n",
      "なり\t246\n",
      "彼\t240\n",
      "｜\t235\n",
      "これ\t235\n",
      "日\t234\n",
      "五\t234\n",
      "なる\t229\n",
      "でも\t228\n",
      "——\t221\n",
      "や\t218\n",
      "という\t218\n",
      "やう\t215\n",
      "ゐる\t212\n",
      "もう\t212\n",
      "出\t208\n",
      "さん\t198\n",
      "言っ\t198\n",
      "だけ\t193\n",
      "ござい\t191\n",
      "上\t180\n",
      "なく\t178\n",
      "たち\t176\n",
      "しかし\t175\n",
      "られ\t173\n",
      "ゐ\t169\n",
      "あなた\t166\n",
      "假名\t165\n",
      "前\t162\n",
      "いい\t160\n",
      "また\t160\n",
      "たら\t159\n",
      "ひ\t158\n",
      "たり\t156\n",
      "家\t156\n",
      "ばかり\t155\n",
      "声\t154\n",
      "自分\t151\n",
      "思っ\t145\n",
      "など\t144\n",
      "いや\t143\n",
      "夫\t143\n",
      "…\t142\n",
      "手\t142\n",
      "遣\t141\n",
      "じゃ\t138\n",
      "なかっ\t137\n",
      "より\t134\n",
      "それから\t134\n",
      "おれ\t134\n",
      "ので\t131\n",
      "気\t131\n",
      "たる\t130\n",
      "心\t127\n",
      "る\t127\n",
      "君\t126\n",
      "どう\t125\n",
      "見る\t120\n",
      "年\t118\n",
      "あたし\t118\n",
      "目\t116\n",
      "少し\t115\n",
      "さちよ\t114\n",
      "話\t113\n",
      "今\t112\n",
      "とき\t112\n",
      "出し\t111\n",
      "まだ\t111\n",
      "ひと\t111\n",
      "外\t110\n",
      "様\t108\n",
      "位\t107\n",
      "又\t107\n",
      "たい\t107\n",
      "余\t107\n",
      "けれども\t106\n",
      "方\t105\n",
      "わたし\t105\n",
      "間\t103\n",
      "一つ\t101\n",
      "僕\t101\n",
      "眼\t100\n",
      "所\t99\n",
      "保吉\t98\n",
      "我\t97\n",
      "居る\t97\n",
      "まま\t96\n",
      "かけ\t96\n",
      "誰\t96\n",
      "云う\t96\n",
      "こう\t95\n",
      "だっ\t95\n",
      "そんな\t95\n",
      "お前\t94\n",
      "者\t93\n",
      "いま\t93\n",
      "くれ\t92\n",
      "ため\t92\n",
      "れる\t92\n",
      "あつ\t91\n",
      "犬\t91\n",
      "後\t90\n",
      "言う\t88\n",
      "わ\t88\n",
      "彼女\t88\n",
      "来る\t87\n",
      "出来\t87\n",
      "的\t87\n",
      "六\t86\n",
      "らしい\t86\n",
      "下\t85\n",
      "でしょ\t85\n",
      "店\t84\n",
      "口\t84\n",
      "ところ\t84\n",
      "ほど\t83\n",
      "なかつ\t83\n",
      "あれ\t83\n",
      "なけれ\t83\n",
      "でし\t83\n",
      "下さい\t82\n",
      "どこ\t81\n",
      "居り\t81\n",
      "ひとり\t81\n",
      "あ\t80\n",
      "無い\t80\n",
      "くらい\t80\n",
      "として\t79\n",
      "うち\t77\n",
      "聞い\t77\n",
      "右\t77\n",
      "知れ\t76\n",
      "感じ\t76\n",
      "ここ\t76\n",
      "メロス\t76\n",
      "言い\t75\n",
      "だろ\t75\n",
      "思う\t75\n",
      "思ひ\t74\n",
      "思ふ\t74\n",
      "行\t74\n",
      "つた\t73\n",
      "き\t73\n",
      "同じ\t73\n",
      "知ら\t73\n",
      "四\t73\n",
      "ただ\t73\n",
      "ふと\t72\n",
      "見え\t72\n",
      "言葉\t72\n",
      "父\t72\n",
      "すぐ\t71\n",
      "行っ\t71\n",
      "そこ\t71\n",
      "身\t71\n",
      "のに\t70\n",
      "忠利\t70\n",
      "そうして\t69\n",
      "ご\t69\n",
      "國\t69\n",
      "度\t68\n",
      "光\t68\n",
      "信子\t68\n",
      "七\t68\n",
      "やはり\t67\n",
      "大\t67\n",
      "まい\t67\n",
      "だって\t67\n",
      "ほう\t67\n",
      "來\t67\n",
      "是\t67\n",
      "主人\t66\n",
      "物\t66\n",
      "すると\t66\n",
      "つけ\t66\n",
      "にて\t66\n",
      "程\t65\n",
      "馬\t65\n",
      "ぢ\t64\n",
      "！\t64\n",
      "子\t64\n",
      "こんな\t63\n",
      "百\t63\n",
      "知っ\t63\n",
      "しまっ\t63\n",
      "思い\t63\n",
      "人間\t63\n",
      "ども\t63\n",
      "夜\t62\n",
      "ねえ\t62\n",
      "かも\t61\n",
      "なつ\t61\n",
      "母\t61\n",
      "仁\t61\n",
      "之\t61\n",
      "郎\t61\n",
      "田島\t61\n",
      "しよ\t60\n",
      "酒\t60\n",
      "さえ\t60\n",
      "考え\t60\n",
      "部屋\t60\n",
      "頃\t59\n",
      "立っ\t58\n",
      "頭\t58\n",
      "殉死\t58\n",
      "なん\t58\n",
      "衛門\t58\n",
      "好い\t57\n",
      "み\t57\n",
      "本\t57\n",
      "語\t57\n",
      "或\t56\n",
      "内\t56\n",
      "風\t56\n",
      "ゝ\t56\n",
      "どうも\t55\n",
      "歩い\t55\n",
      "色\t54\n",
      "のみ\t54\n",
      "とも\t54\n",
      "婆さん\t54\n",
      "言\t54\n",
      "利\t54\n",
      "持っ\t54\n",
      "斯\t54\n",
      "妻\t53\n",
      "やっ\t53\n",
      "姫君\t53\n",
      "わたくし\t53\n",
      "自身\t52\n",
      "ああ\t52\n",
      "よく\t52\n",
      "皆\t52\n",
      "そこで\t52\n",
      "姫\t52\n",
      "其の\t52\n",
      "勿論\t51\n",
      "々\t51\n",
      "死ん\t51\n",
      "行く\t51\n",
      "り\t51\n",
      "申し\t51\n",
      "八\t51\n",
      "髪長\t51\n",
      "彦\t51\n",
      "通り\t50\n",
      "）\t50\n",
      "あら\t50\n",
      "ぞ\t50\n",
      "笑っ\t50\n",
      "いっ\t50\n",
      "※\t50\n",
      "侍\t50\n",
      "此\t50\n",
      "とか\t49\n",
      "石\t49\n",
      "やら\t49\n",
      "数枝\t49\n",
      "（\t48\n",
      "朝\t48\n",
      "氏\t48\n",
      "姿\t47\n",
      "居\t47\n",
      "いけ\t47\n",
      "はいっ\t47\n",
      "べき\t47\n",
      "青年\t47\n",
      "って\t47\n",
      "半\t47\n",
      "得\t47\n",
      "わけ\t47\n",
      "でき\t47\n",
      "まあ\t46\n",
      "用\t46\n",
      "阿部\t46\n",
      "かう\t45\n",
      "忘れ\t45\n",
      "先\t45\n",
      "帰っ\t45\n",
      "それでも\t45\n",
      "早く\t45\n",
      "どんな\t45\n",
      "弟\t45\n",
      "ちょっと\t45\n",
      "キヌ子\t45\n",
      "大谷\t45\n",
      "彼等\t44\n",
      "足\t44\n",
      "め\t44\n",
      "山\t44\n",
      "常子\t44\n",
      "悪い\t43\n",
      "ら\t43\n",
      "耳\t43\n",
      "音\t43\n",
      "つい\t43\n",
      "胸\t43\n",
      "道\t43\n",
      "窓\t42\n",
      "違\t42\n",
      "ふも\t42\n",
      "子供\t42\n",
      "とうとう\t42\n",
      "神\t42\n",
      "命\t42\n",
      "聞え\t42\n",
      "行き\t42\n",
      "婆\t42\n",
      "あろ\t42\n",
      "少女\t42\n",
      "思わ\t42\n",
      "わから\t42\n",
      "涙\t42\n",
      "様子\t42\n",
      "数馬\t42\n",
      "乙彦\t42\n",
      "有\t41\n",
      "られる\t41\n",
      "歳\t41\n",
      "相手\t40\n",
      "火\t40\n",
      "書い\t40\n",
      "昔\t40\n",
      "今日\t40\n",
      "ほか\t40\n",
      "はじめ\t40\n",
      "伊織\t40\n",
      "なんて\t40\n",
      "例\t39\n",
      "空\t39\n",
      "遠藤\t39\n",
      "妹\t39\n",
      "く\t39\n",
      "生活\t38\n",
      "やつ\t38\n",
      "唯\t38\n",
      "円\t38\n",
      "信じ\t38\n",
      "なれ\t38\n",
      "こそ\t38\n",
      "名\t38\n",
      "いつも\t38\n",
      "ましょ\t38\n",
      "照子\t38\n",
      "ストップワードを除外した後の行数：8876\n",
      "ユニークな単語の数：13511\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6-7 単語ベクトルの重み付け\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "TF & =\\frac{文書内で単語tが現れる回数}{文書内の単語数}\\\\\n",
    "IDF & =-\\log_{10}\\frac{文書内で単語tを含む文章数}{文書内の文章数} =\\log_{10}\\frac{文書内の文章数}{文章内で単語tを含む文章数}\\\\\n",
    "TF-IDF & =TF\\cdot IDF=\\frac{文書内で単語tが現れる回数}{文書内の単語数}\\log_{10}\\frac{文書内の文章数}{文書内で単語tを含む文章数}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "例：\n",
    "- 1000文からなり、単語数10,000個の文書\n",
    "- ある単語が文書内で100文、120回出現\n",
    "$$\n",
    "\\begin{align*}\n",
    "TF & =\\frac{120}{10000}=0.012\\\\\n",
    "IDF & =-\\log_{10}\\frac{1000}{100}=\\log_{10}10^1=1\\\\\n",
    "\\end{align*}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6-9 完成したモデルの評価"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import csv\n",
    "\n",
    "import gensim\n",
    "from gensim import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def main():\n",
    "    texts, label_ids, id2label = read_copus_file()\n",
    "\n",
    "    #　テキストとラベルのデータをtrain, testに分割します\n",
    "    X_train_texts, X_test_texts, y_train, y_test = train_test_split(texts, label_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # テキストデータから辞書を作成します\n",
    "    dictionary = gensim.corpora.Dictionary(X_train_texts)\n",
    "\n",
    "    # train, testのテキストデータから、tfidfで重み付けされた単語文書行列を作成します\n",
    "    X_train_tfidf, tfidf_model = texts_to_tfidf(dictionary, X_train_texts)\n",
    "    X_test_tfidf, _ = texts_to_tfidf(dictionary, X_test_texts, tfidf_model)\n",
    "\n",
    "    # trainデータを用いて分類器を構築します\n",
    "    clf = LogisticRegression(C=1, penalty='l2')\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # testデータを用いて分類器の精度を評価します\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    target_names = list(id2label.values())\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "def read_copus_file():\n",
    "    with open(CORPUS_FILE, \"r\") as f:\n",
    "        corpus_data = list(csv.reader(f))\n",
    "\n",
    "    # label: author(akutagawa, mori, dazai)\n",
    "    # texts: corpusファイル各行の単語のlist\n",
    "    # label_ids: corpusファイル各行のauthor_id(0, 1, 2)のlist\n",
    "    # label2id: key: author, value: author_idのdict\n",
    "    # sum_words: 重複を含む文字のlist\n",
    "    texts, label_ids = [], []\n",
    "    label2id = {}\n",
    "    idx_label, idx_sentence = 0, 1\n",
    "    sum_words = []\n",
    "\n",
    "    for index, row in enumerate(corpus_data):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        label = row[idx_label]\n",
    "        if label not in label2id:\n",
    "            label2id[label] = len(label2id)\n",
    "        label_ids.append(label2id[label])\n",
    "        word_list = row[idx_sentence].split(\" \")\n",
    "        texts.append(word_list)\n",
    "\n",
    "        for line in word_list:\n",
    "            for word in line:\n",
    "                sum_words.append(word)\n",
    "\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    return texts, label_ids, id2label\n",
    "\n",
    "\n",
    "def texts_to_tfidf(dictionary, texts, model = None):\n",
    "    \"\"\"テキストデータから、tfidfで重み付けされた単語文書行列を作成する\"\"\"\n",
    "    # 辞書を用いてBoW形式に文章を行列化します\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # BoW形式で作成したcorpusをtfidfを用いて重み付けします\n",
    "    if model is None:\n",
    "        model = models.TfidfModel(corpus)\n",
    "    tfidf_corpus = model[corpus]\n",
    "\n",
    "    num_words = len(dictionary)\n",
    "    tfidf = gensim.matutils.corpus2dense(tfidf_corpus, num_terms=num_words).T\n",
    "    return tfidf, model\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   akutagawa       0.85      0.70      0.77       532\n",
      "        mori       0.89      0.67      0.76       485\n",
      "       dazai       0.73      0.94      0.82       758\n",
      "\n",
      "    accuracy                           0.79      1775\n",
      "   macro avg       0.82      0.77      0.78      1775\n",
      "weighted avg       0.81      0.79      0.79      1775\n",
      "\n",
      "[[372  23 137]\n",
      " [ 33 325 127]\n",
      " [ 31  18 709]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd98c0a47dd100ed327505f6f45da449c503b4a1cc6d24b570697723ca77c06b"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('.venv': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}